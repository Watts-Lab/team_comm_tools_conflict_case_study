# Conflict Companion Case Study for the `team_comm_tools` paper

This repository contains the full code and supporting data for the conflict management case study presented in our paper, where we apply the TCT (Team Communication Toolkit, or `team_comm_tools`) package to analyze features that signal escalation, directness, and oppositional intensity in online conversations.

## Repo Structure
This repository is structured as follows:

```
├── README.md
├── conflict_case_study.ipynb         # Main analysis notebook (case study code)
├── feature_lists.py                  # Auxiliar file with feature lists/scripts for analysis
├── input-files/                      
│   ├── CONFLICT_CONVO_LABELING_LOG.csv # hand-labeled directness and oppositional intensity
│   ├── data_to_label_reddit_sample.csv # original utterances that raters were given to label
│   ├── gpt_data.csv # GPT-generated conversations
│   └── reddit_data.csv # Reddit conversations
│   
├── output/ # Processed data, results, and models
│   ├── chat/ # TCT utterance-level outputs
│   │   ├── combined_reddit_output_chat_level_balanced.csv
│   │   ├── gpt_output_chat_level.csv
│   │   └── labeled_utterances_reddit_chat_level.csv
│   ├── conv/ # TCT conversation-level outputs
│   │   ├── gpt_output_conv_level.csv
│   │   └── labeled_utterances_reddit_conv_level.csv
│   ├── user/ # TCT speaker-level outputs
│   │   ├── combined_reddit_output_user_level.csv
│   │   ├── gpt_output_user_level.csv
│   │   └── labeled_utterances_reddit_user_level.csv
│   ├── *results, models, plots, and coefficients for various analyses*
│   ├── predict_gpt_labels_model_records.pkl        # Large, ignored
│   ├── predict_utt_labels_model_records.pkl        # Large, ignored
│   ├── predict_reddit_chat_labels_model_records.pkl# Large, ignored
│   └── (...other processed results and plots...)
└── vector_data/ # Cache for semantic vectors and RoBERTa sentiments
    ├── sentence/
    │   └── chats/
    └── sentiment/
        └── chats/
```

### Key Files

- README.md
- conflict_case_study.ipynb 
- input-files/         
- output/             
- vector_data/         

## Case Study Summary

In this case study, we used the TCT package to analyze and model conversational conflict using real (Reddit) and synthetic (GPT) forum dialogue data. We examine what features predict directness and oppositional intensity (part 1), and what predicts the overall esalation of a conflict in conversations (part 2).

## Dataset Overview

### Source Data:

- **r/ChangeMyView Reddit Data**  
  - Curated by Chang & Danescu-Niculescu-Mizil (2019) and Tan et al. (2016).
    - [Original Winning Arguments Corpus (Tan et al., 2016)](https://convokit.cornell.edu/documentation/winning.html)
    - [Original Conversations Gone Awry Corpus (Chang & Danescu-Niculescu-Mizil, 2019)](https://convokit.cornell.edu/documentation/awry_cmv.html)
  - Contains conversations that either "go awry" (escalate) or "succeed" (de-escalate, with Deltas awarded for persuasion).

- **Synthetic GPT Data**  
  - 1,200 conversations generated by GPT-4 (see D’Costa et al., 2024).

### Main Analyses

1. **Utterance-Level Annotation and Modeling:**  
   *Goal:* What linguistic features signal directness and opposition at the utterance level?  
   - Sampled 121 Reddit conversations (both escalatory and 'winning').
   - Split into ~1,000 utterances and annotated them for:
     - Direct Content
     - Direct Expression
     - Oppositionally Intense Content
     - Oppositionally Intense Expression
   - Built models using TCT features to predict these labels.

2. **Conversation-Level Escalation/De-Escalation Modeling:**  
   *Goal:* What features distinguish escalatory vs. de-escalatory conversations?  
   - Sample of 4,198 Reddit conversations and 1,200 GPT conversations.
   - Classified conversations as escalatory (gone awry) vs. de-escalatory (winning).
   - Modeled escalation as a binary outcome using TCT features.

## To reproduce the analyses in the case study

  1. See the main notebook: `conflict_case_study.ipynb`.
  2. Required data is in `input-files/`.
  3. Intermediate results stored in `output/` and `vector_data/`.

## File Notes

- Some large model and result files (`*.pkl`, some `output/*csv`) are >100MB and excluded from version history.
- Add your own large files to `.gitignore` if running on new data.

## References

- Chang, J. P., & Danescu-Niculescu-Mizil, C. (2019). Trouble on the Horizon: Forecasting the Derailment of Online Conversations as they Develop (arXiv:1909.01362). arXiv. https://doi.org/10.48550/arXiv.1909.01362
- Tan, C., Niculae, V., Danescu-Niculescu-Mizil, C., & Lee, L. (2016). Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions. Proceedings of the 25th International Conference on World Wide Web, 613–624. https://doi.org/10.1145/2872427.2883081
- D’Costa, P. R., Rowbotham, E., & Hu, X. E. (2024). What you say or how you say it? Predicting Conflict Outcomes in Real and LLM-Generated Conversations (arXiv:2409.09338). arXiv. https://doi.org/10.48550/arXiv.2409.09338